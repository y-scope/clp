nameOverride: ""
fullnameOverride: ""

# Whether to allow scripts in `sbin` access to services on the host.
allowHostAccessForSbinScripts: true

securityContext:
  firstParty:
    uid: 1000
    gid: 1000
  thirdParty:
    uid: 1000
    gid: 1000

image:
  clpPackage:
    repository: "ghcr.io/y-scope/clp/clp-package"
    pullPolicy: "Always"
    tag: "main"

workerConcurrency: 8

clpConfig:
  package:
    storage_engine: "clp"
    query_engine: "clp"

  # Location (e.g., directory) containing any logs you wish to compress. Must be reachable by all
  # workers.
  logs_input:
    type: "fs"

    # NOTE: This directory will be exposed inside the container, so symbolic links to files outside
    # this directory will be ignored.
    directory: "/"

  bundled: ["database", "queue", "redis", "results_cache"]

  database:
    type: "mariadb"  # "mariadb" or "mysql"
    port: 30306
    names:
      clp: "clp-db"

  compression_scheduler:
    jobs_poll_delay: 0.1  # seconds
    logging_level: "INFO"
    max_concurrent_tasks_per_job: 0  # A value of 0 disables the limit
    type: "celery"  # "celery" or "spider"

  query_scheduler:
    jobs_poll_delay: 0.1  # seconds
    num_archives_to_search_per_sub_job: 16
    logging_level: "INFO"

  redis:
    query_backend_database: 0
    compression_backend_database: 1

  reducer:
    logging_level: "INFO"
    upsert_interval: 100  # milliseconds

  results_cache:
    port: 30017
    db_name: "clp-query-results"
    stream_collection_name: "stream-files"

    # Retention period for search results, in minutes. Set to null to disable automatic deletion.
    retention_period: 60

  compression_worker:
    logging_level: "INFO"

  query_worker:
    logging_level: "INFO"

  webui:
    port: 30000
    results_metadata_collection_name: "results-metadata"
    rate_limit: 1000

  mcp_server: null
  #   port: 30800
  #   logging_level: "INFO"

  # Where archives should be output to
  archive_output:
    storage:
      type: "fs"
      # NOTE: This directory must not overlap with any path used in CLP's execution container. An
      # error will be raised if so.
      directory: "/tmp/clp/var/data/archives"

    # Retention period for archives, in minutes. Set to null to disable automatic deletion.
    retention_period: null

    # How much data CLP should try to compress into each archive
    target_archive_size: 268435456  # 256 MB

    # How large the dictionaries should be allowed to get before the archive is
    # closed and a new one is created
    target_dictionaries_size: 33554432  # 32 MB

    # How large each encoded file should be before being split into a new encoded
    # file
    target_encoded_file_size: 268435456  # 256 MB

    # How much data CLP should try to fit into each segment within an archive
    target_segment_size: 268435456  # 256 MB

    # How much archives should be compressed: 1 (fast/low compression) to 19 (slow/high compression)
    compression_level: 3

  # Where CLP stream files (e.g., IR streams) should be output
  stream_output:
    storage:
      type: "fs"
      # NOTE: This directory must not overlap with any path used in CLP's execution container. An
      # error will be raised if so.
      directory: "/tmp/clp/var/data/streams"

    # How large each stream file should be before being split into a new stream file
    target_uncompressed_size: 134217728  # 128 MB

  # Garbage collector config
  garbage_collector:
    logging_level: "INFO"

    # Interval (in minutes) at which garbage collector jobs run
    sweep_interval:
      archive: 60
      search_result: 30

  # API server config
  api_server: null

  # log-ingestor config. Currently, the config is applicable only if `logs_input.type` is "s3".
  log_ingestor: null

  # Fluent Bit config for centralized operational logging.
  # When enabled, Fluent Bit collects logs from all CLP components and:
  # - Stores them in organized file storage (hot tier) for real-time access
  # - Optionally uploads to S3 (cold tier) for archival with CLP compression
  fluent_bit: null
  #   enabled: true
  #   image:
  #     repository: "fluent/fluent-bit"
  #     tag: "3.2"
  #     pullPolicy: "IfNotPresent"
  #   logging_level: "info"  # error, warning, info, debug, trace
  #   flush_interval: 5  # seconds
  #   refresh_interval: 10  # seconds (how often to check for new log files)
  #   storage_size: "10Gi"  # size of operational logs PVC
  #   resources:
  #     limits:
  #       cpu: "100m"
  #       memory: "50Mi"
  #     requests:
  #       cpu: "50m"
  #       memory: "25Mi"
  #   debug_output: false  # enable stdout output for debugging
  #   s3_output: null  # optional S3 output for cold tier archival
  #     # enabled: true
  #     # bucket: "my-operational-logs-bucket"
  #     # region: "us-east-1"
  #     # key_prefix: "operational-logs"
  #     # endpoint: null  # optional custom S3 endpoint
  #     # total_file_size: "10M"  # size before uploading to S3
  #     # upload_timeout: "5m"  # max time before uploading to S3
  #     # auth_type: "profile"  # or "credentials"
  #     # profile: "default"  # AWS profile name (if auth_type is "profile")

  # Presto client config
  presto: null
  #   host: "localhost"
  #   port: 8080

  # Location where other data (besides archives) are stored. It will be created if
  # it doesn't exist.
  # NOTE: This directory must not overlap with any path used in CLP's execution container. An error
  # will be raised if so.
  data_directory: "/tmp/clp/var/data"

  # Location where logs are stored. It will be created if it doesn't exist.
  # NOTE: This directory must not overlap with any path used in CLP's execution container. An error
  # will be raised if so.
  logs_directory: "/tmp/clp/var/log"

  # Location where temporary runtime data are stored. It will be created if
  # it doesn't exist.
  # NOTE: This directory must not overlap with any path used in CLP's execution container. An error
  # will be raised if so.
  tmp_directory: "/tmp/clp/var/tmp"

  # Location of the AWS tools' config files (e.g., `~/.aws`)
  aws_config_directory: null

credentials:
  database:
    username: "clp-user"
    password: "pass"
    root_username: "root"
    root_password: "root-pass"

  queue:
    username: "clp-user"
    password: "pass"

  redis:
    password: "pass"
