## A path containing any logs you which to compress. Must be reachable by all
## workers.
## - This path will be exposed inside the container, so symbolic links to files
##   outside this path will be ignored.
#input_logs_directory: "/"
#
## File containing credentials for services
#credentials_file_path: "etc/credentials.yml"
#
#package:
#  storage_engine: "clp"
#
#database:
#  type: "mariadb"  # "mariadb" or "mysql"
#  host: "localhost"
#  port: 3306
#  name: "clp-db"
#
#compression_scheduler:
#  jobs_poll_delay: 0.1  # seconds
#  logging_level: "INFO"
#
#query_scheduler:
#  host: "localhost"
#  port: 7000
#  jobs_poll_delay: 0.1  # seconds
#  num_archives_to_search_per_sub_job: 16
#  logging_level: "INFO"
#
#queue:
#  host: "localhost"
#  port: 5672
#
#redis:
#  host: "localhost"
#  port: 6379
#  query_backend_database: 0
#  compression_backend_database: 1
#
#reducer:
#  host: "localhost"
#  base_port: 14009
#  logging_level: "INFO"
#  upsert_interval: 100  # milliseconds
#
#results_cache:
#  host: "localhost"
#  port: 27017
#  db_name: "clp-query-results"
#  stream_collection_name: "stream-files"
#
#compression_worker:
#  logging_level: "INFO"
#
#query_worker:
#  logging_level: "INFO"
#
#webui:
#  host: "localhost"
#  port: 4000
#  logging_level: "INFO"
#
#log_viewer_webui:
#  host: "localhost"
#  port: 3000
#
## Where archives should be output to
#archive_output:
#  storage:
#    type: "fs"
#    directory: "var/data/archives"
#
#  # How much data CLP should try to compress into each archive
#  target_archive_size: 268435456  # 256 MB
#
#  # How large the dictionaries should be allowed to get before the archive is
#  # closed and a new one is created
#  target_dictionaries_size: 33554432  # 32 MB
#
#  # How large each encoded file should be before being split into a new encoded
#  # file
#  target_encoded_file_size: 268435456  # 256 MB
#
#  # How much data CLP should try to fit into each segment within an archive
#  target_segment_size: 268435456  # 256 MB
#
## Where CLP stream files (e.g., IR streams) should be output
#stream_output:
#  storage:
#    type: "fs"
#    directory: "var/data/streams"
#
#  # How large each stream file should be before being split into a new stream file
#  target_uncompressed_size: 134217728  # 128 MB
#
## Location where other data (besides archives) are stored. It will be created if
## it doesn't exist.
#data_directory: "var/data"
#
## Location where logs are stored. It will be created if it doesn't exist.
#logs_directory: "var/log"
