#!/usr/bin/env python3
import argparse
import logging
import multiprocessing
import os
import pathlib
import subprocess
import sys
import time
import typing
import uuid

# Setup logging
# Create logger
logger = logging.getLogger('clp')
logger.setLevel(logging.INFO)
# Setup console logging
logging_console_handler = logging.StreamHandler()
logging_formatter = logging.Formatter('%(asctime)s [%(levelname)s] [%(name)s] %(message)s')
logging_console_handler.setFormatter(logging_formatter)
logger.addHandler(logging_console_handler)


def get_clp_home():
    clp_home = None
    if 'CLP_HOME' in os.environ:
        clp_home = pathlib.Path(os.environ['CLP_HOME'])
    else:
        for path in pathlib.Path(__file__).resolve().parents:
            if 'sbin' == path.name:
                clp_home = path.parent
                break

    if clp_home is None:
        logger.error('CLP_HOME is not set and could not be determined automatically.')
        return None
    elif not clp_home.exists():
        logger.error('CLP_HOME does not exist.')
        return None

    return clp_home.resolve()


def load_bundled_python_lib_path(clp_home):
    python_site_packages_path = clp_home / 'lib' / 'python3' / 'site-packages'
    if not python_site_packages_path.is_dir():
        logger.error('Failed to load python3 packages bundled with CLP.')
        return -1
    # Add packages to the front of the path
    sys.path.insert(0, str(python_site_packages_path))


clp_home = get_clp_home()
if clp_home is None:
    sys.exit(-1)
load_bundled_python_lib_path(clp_home)

from clp.package_utils import \
    check_dependencies, \
    container_exists, \
    CONTAINER_CLP_INSTALL_PREFIX, \
    DockerMount, \
    DockerMountType, \
    generate_container_config, \
    make_config_path_absolute, \
    validate_or_generate_config_file
from clp_py_utils.clp_config import CLPConfig


def wait_for_database_to_init(container_name, clp_config: CLPConfig, timeout: int):
    # Try to connect to the database
    begin_time = time.time()
    container_exec_cmd = [
        'docker', 'exec',
        '-it',
        container_name
    ]
    mysqladmin_cmd = [
        'mysqladmin', 'ping',
        '--silent',
        '--socket', str("/var/run/mysqld/mysqld.sock"),
        '-u', str(clp_config.database.username),
        f'--password={clp_config.database.password}'
    ]
    cmd = container_exec_cmd + mysqladmin_cmd
    while True:
        try:
            subprocess.run(cmd, stdout=subprocess.DEVNULL, check=True)
            return True
        except subprocess.CalledProcessError:
            if time.time() - begin_time > timeout:
                break
            time.sleep(1)

    logger.error("Timeout while waiting for database.")
    return False


def start_db(instance_id: str, clp_config: CLPConfig, conf_dir: pathlib.Path, data_dir: pathlib.Path,
             logs_dir: pathlib.Path):
    logger.info(f'Starting database...')

    container_name = f'clp-db-{instance_id}'
    if container_exists(container_name):
        logger.info(f'Database already running.')
        return

    # Create directories
    db_data_dir = data_dir / 'db'
    db_data_dir.mkdir(exist_ok=True, parents=True)
    db_logs_dir = logs_dir / 'mysql-logs'
    db_logs_dir.mkdir(exist_ok=True, parents=True)

    # Start container
    mounts = [
        DockerMount(DockerMountType.BIND, conf_dir / 'mysql', pathlib.Path('/') / 'etc' / 'mysql' / 'conf.d', True),
        DockerMount(DockerMountType.BIND, db_data_dir, pathlib.Path('/') / 'var' / 'lib' / 'mysql'),
        DockerMount(DockerMountType.BIND, db_logs_dir, pathlib.Path('/') / 'var' / 'log' / 'mysql'),
    ]
    database_startup_cmd = [
        'docker', 'run',
        '-d',
        '--rm',
        '--name', container_name,
        '-e', f'MYSQL_ROOT_PASSWORD={clp_config.database.password}',
        '-e', f'MYSQL_USER={clp_config.database.username}',
        '-e', f'MYSQL_PASSWORD={clp_config.database.password}',
        '-e', f'MYSQL_DATABASE=initial_database',
        '-u', f'{os.getuid()}:{os.getgid()}',
        '-p', f'{clp_config.database.host}:{clp_config.database.port}:3306',
    ]
    for mount in mounts:
        database_startup_cmd.append('--mount')
        database_startup_cmd.append(str(mount))
    if 'mysql' == clp_config.database.type:
        database_startup_cmd.append('mysql:8.0.23')
    elif 'mariadb' == clp_config.database.type:
        database_startup_cmd.append('mariadb:10.6.4-focal')
    subprocess.run(database_startup_cmd, stdout=subprocess.DEVNULL, check=True)

    if not wait_for_database_to_init(container_name, clp_config, 30):
        raise EnvironmentError("Database did not initialize in time")

    logger.info(f'Started database.')


def create_db_tables(instance_id: str, docker_clp_home: pathlib.Path, mounts: typing.List[DockerMount],
                     container_clp_config: CLPConfig):
    logger.info('Creating database tables...')

    container_config_filename = '.clp-table-creator-config.yaml'
    container_config_file_path = clp_home / 'etc' / container_config_filename
    with open(container_config_file_path, 'w') as f:
        f.write(container_clp_config.generate_config_file_content_with_comments())

    container_name = f'clp-db-table-creator-{instance_id}'
    clp_site_packages_dir = docker_clp_home / 'lib' / 'python3' / 'site-packages'
    container_start_cmd = [
        'docker', 'run',
        '-i',
        '--network', 'host',
        '--rm',
        '--name', container_name,
        '-e', f'PYTHONPATH={clp_site_packages_dir}',
        '-u', f'{os.getuid()}:{os.getgid()}',
    ]
    for mount in mounts:
        container_start_cmd.append('--mount')
        container_start_cmd.append(str(mount))
    container_start_cmd.append('ghcr.io/y-scope/clp/clp-execution-x86-ubuntu-focal:main')

    clp_py_utils_dir = clp_site_packages_dir / 'clp_py_utils'
    create_tables_cmd = [
        'python3',
        f'{clp_py_utils_dir / "create-db-tables.py"}',
        '--config', str(docker_clp_home / 'etc' / container_config_filename),
        '--timeout', str(30)
    ]

    cmd = container_start_cmd + create_tables_cmd
    logger.debug(' '.join(cmd))
    subprocess.run(cmd, stdout=subprocess.DEVNULL, check=True)

    container_config_file_path.unlink()

    logger.info('Created database tables.')


def start_scheduler_queue(instance_id: str, clp_config: CLPConfig, conf_dir: pathlib.Path, logs_dir: pathlib.Path):
    logger.info(f'Starting scheduler queue...')

    container_name = f'clp-queue-{instance_id}'
    if container_exists(container_name):
        logger.info(f'Scheduler queue already running.')
        return

    log_filename = 'rabbitmq.log'

    # Generate config file
    config_filename = 'rabbitmq.conf'
    host_config_file_path = conf_dir / config_filename
    with open(conf_dir / config_filename, 'w') as f:
        # f.write(f'listeners.tcp.default = 5672\n')
        f.write(f'default_user = {clp_config.scheduler_queue.username}\n')
        f.write(f'default_pass = {clp_config.scheduler_queue.password}\n')
        f.write(f'log.file = {log_filename}\n')

    # Create directories
    host_rabbitmq_logs_dir = logs_dir / 'rabbitmq'
    host_rabbitmq_logs_dir.mkdir(exist_ok=True, parents=True)

    # Start container
    rabbitmq_logs_dir = pathlib.Path('/') / 'var' / 'log' / 'rabbitmq'
    mounts = [
        DockerMount(DockerMountType.BIND, host_config_file_path,
                    pathlib.Path('/') / 'etc' / 'rabbitmq' / 'rabbitmq.conf', True),
        DockerMount(DockerMountType.BIND, host_rabbitmq_logs_dir, rabbitmq_logs_dir),
    ]
    rabbitmq_pid_file_path = pathlib.Path('/') / 'tmp' / 'rabbitmq.pid'
    cmd = [
        'docker', 'run',
        '-d',
        '--rm',
        '--name', container_name,
        # Override RABBITMQ_LOGS since the image sets it to *only* log to stdout
        '-e', f'RABBITMQ_LOGS={rabbitmq_logs_dir / log_filename}',
        '-e', f'RABBITMQ_PID_FILE={rabbitmq_pid_file_path}',
        '-u', f'{os.getuid()}:{os.getgid()}',
        '-p', f'{clp_config.scheduler_queue.host}:{clp_config.scheduler_queue.port}:5672',
    ]
    for mount in mounts:
        cmd.append('--mount')
        cmd.append(str(mount))
    cmd.append('rabbitmq:3.9.8')
    subprocess.run(cmd, stdout=subprocess.DEVNULL, check=True)

    # Wait for queue to start up
    cmd = [
        'docker', 'exec', '-it', container_name,
        'rabbitmqctl', 'wait', str(rabbitmq_pid_file_path),
    ]
    subprocess.run(cmd, stdout=subprocess.DEVNULL, check=True)

    logger.info(f'Started scheduler queue.')


def start_scheduler(instance_id: str, docker_clp_home: pathlib.Path, mounts: typing.List[DockerMount],
                    container_clp_config: CLPConfig):
    logger.info('Starting scheduler...')

    container_name = f'clp-scheduler-{instance_id}'
    if container_exists(container_name):
        logger.info(f'Scheduler already running.')
        return

    container_config_filename = '.clp-scheduler-config.yaml'
    container_config_file_path = clp_home / 'etc' / container_config_filename
    with open(container_config_file_path, 'w') as f:
        f.write(container_clp_config.generate_config_file_content_with_comments())

    clp_site_packages_dir = docker_clp_home / 'lib' / 'python3' / 'site-packages'
    container_start_cmd = [
        'docker', 'run',
        '-di',
        '--network', 'host',
        '-w', str(docker_clp_home),
        '--rm',
        '--name', container_name,
        '-e', f'PYTHONPATH={clp_site_packages_dir}',
        '-e', f'BROKER_URL=amqp://'
              f'{container_clp_config.scheduler_queue.username}:{container_clp_config.scheduler_queue.password}@'
              f'{container_clp_config.scheduler_queue.host}:{container_clp_config.scheduler_queue.port}',
        '-u', f'{os.getuid()}:{os.getgid()}',
    ]
    for mount in mounts:
        container_start_cmd.append('--mount')
        container_start_cmd.append(str(mount))
    container_start_cmd.append('ghcr.io/y-scope/clp/clp-execution-x86-ubuntu-focal:main')

    scheduler_cmd = [
        f'python3', '-u', '-m',
        'job_orchestration.scheduler.scheduler',
        f'--config', f'{docker_clp_home / "etc" / container_config_filename}',
    ]
    cmd = container_start_cmd + scheduler_cmd
    subprocess.run(cmd, stdout=subprocess.DEVNULL, check=True)

    logger.info('Started scheduler.')


def start_worker(instance_id: str, docker_clp_home: pathlib.Path, mounts: typing.List[DockerMount],
                 container_clp_config: CLPConfig, num_cpus: int):
    logger.info('Starting worker...')

    container_name = f'clp-worker-{instance_id}'
    if container_exists(container_name):
        logger.info(f'Worker already running.')
        return

    clp_site_packages_dir = docker_clp_home / 'lib' / 'python3' / 'site-packages'
    container_start_cmd = [
        'docker', 'run',
        '-di',
        '--network', 'host',
        '-w', str(docker_clp_home),
        '--rm',
        '--name', container_name,
        '-e', f'PYTHONPATH={clp_site_packages_dir}',
        '-e', f'BROKER_URL=amqp://'
              f'{container_clp_config.scheduler_queue.username}:{container_clp_config.scheduler_queue.password}@'
              f'{container_clp_config.scheduler_queue.host}:{container_clp_config.scheduler_queue.port}',
        '-e', f'RESULT_BACKEND=rpc://'
              f'{container_clp_config.scheduler_queue.username}:{container_clp_config.scheduler_queue.password}'
              f'@{container_clp_config.scheduler_queue.host}:{container_clp_config.scheduler_queue.port}',
        '-e', f'CLP_HOME={docker_clp_home}',
        '-e', f'CLP_DATA_DIR={container_clp_config.data_directory}',
        '-e', f'CLP_LOGS_DIR={container_clp_config.logs_directory}',
        '-u', f'{os.getuid()}:{os.getgid()}',
    ]
    for mount in mounts:
        container_start_cmd.append('--mount')
        container_start_cmd.append(str(mount))
    container_start_cmd.append('ghcr.io/y-scope/clp/clp-execution-x86-ubuntu-focal:main')

    worker_cmd = [
        str(clp_site_packages_dir / 'bin' / 'celery'),
        '-A',
        'job_orchestration.executor',
        'worker',
        '--concurrency', str(num_cpus),
        '--loglevel', 'WARNING',
        '-Q', 'compression',
    ]
    cmd = container_start_cmd + worker_cmd
    subprocess.run(cmd, stdout=subprocess.DEVNULL, check=True)

    logger.info('Started worker.')


def main(argv):
    default_config_file_path = clp_home / 'etc' / 'clp-config.yaml'

    args_parser = argparse.ArgumentParser(description='Starts CLP')
    args_parser.add_argument('--config', '-c', default=str(default_config_file_path),
                             help='CLP package configuration file.')

    component_args_parser = args_parser.add_subparsers(dest='component_name')
    component_args_parser.add_parser('db')
    component_args_parser.add_parser('queue')
    component_args_parser.add_parser('scheduler')
    worker_args_parser = component_args_parser.add_parser('worker')
    worker_args_parser.add_argument('--num-cpus', type=int, default=0,
                                    help='Number of logical CPU cores to use for compression')

    parsed_args = args_parser.parse_args(argv[1:])

    try:
        check_dependencies()
    except EnvironmentError as ex:
        logger.exception("Dependency checking failed.")
        return -1

    # Validate config file
    config_file_path = pathlib.Path(parsed_args.config)
    clp_config = validate_or_generate_config_file(config_file_path, default_config_file_path)
    if clp_config is None:
        return -1

    if parsed_args.component_name:
        component_name = parsed_args.component_name
    else:
        component_name = ""

    # Validate input_logs_dfs_path
    input_logs_dfs_path = clp_config.input_logs_dfs_path.resolve()
    if not input_logs_dfs_path.exists():
        logger.error(f'Specified `input_logs_dfs_path` doesn\'t exist: {input_logs_dfs_path}')
        return -1
    if not input_logs_dfs_path.is_dir():
        logger.error(f'Specified `input_logs_dfs_path` is not a directory: {input_logs_dfs_path}')
        return -1

    container_clp_config, mounts = generate_container_config(clp_config, clp_home)

    try:
        logs_dir = make_config_path_absolute(clp_home, clp_config.logs_directory)
        logs_dir.mkdir(parents=True, exist_ok=True)

        instance_id_file_path = logs_dir / "instance-id"
        if instance_id_file_path.exists():
            with open(instance_id_file_path, 'r') as f:
                instance_id = f.readline()
        else:
            instance_id = str(uuid.uuid4())[-4:]
            with open(instance_id_file_path, 'w') as f:
                f.write(instance_id)
                f.flush()

        conf_dir = clp_home / 'etc'
        data_dir = make_config_path_absolute(clp_home, clp_config.data_directory)
        logs_dir = make_config_path_absolute(clp_home, clp_config.logs_directory)

        docker_clp_home = pathlib.Path(CONTAINER_CLP_INSTALL_PREFIX) / 'clp'
        if "" == component_name or "db" == component_name:
            start_db(instance_id, clp_config, conf_dir, data_dir, logs_dir)
            create_db_tables(instance_id, docker_clp_home, mounts, container_clp_config)
        if "" == component_name or "queue" == component_name:
            start_scheduler_queue(instance_id, container_clp_config, conf_dir, logs_dir)
        if "" == component_name or "scheduler" == component_name:
            start_scheduler(instance_id, docker_clp_home, mounts, container_clp_config)
        if "" == component_name or "worker" == component_name:
            # Get the number of CPU cores to use
            num_cpus = 0
            # TODO This is a bit messy
            if "worker" == component_name:
                num_cpus = parsed_args.num_cpus
            if 0 == num_cpus:
                num_cpus = multiprocessing.cpu_count()

            start_worker(instance_id, docker_clp_home, mounts, container_clp_config, num_cpus)
    except:
        # Stop CLP
        subprocess.run(['python3', str(clp_home / 'sbin' / 'stop-clp')], check=True)

        logger.exception('Failed to start CLP.')
        return -1

    return 0


if '__main__' == __name__:
    sys.exit(main(sys.argv))
